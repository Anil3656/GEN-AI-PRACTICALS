# -*- coding: utf-8 -*-
"""RAG_with_Gemma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13PlOv5M8ePH7qgwsiI5yhbNpHC-vEKpJ

Builded A Text based RAG Model Without using LLM
"""

!pip install -U \
    chromadb==0.5.15 \
    langchain==0.2.11 \
    langchain-community==0.2.10 \
    langchain-chroma==0.1.4 \
    langchain-text-splitters==0.2.2 \
    langchain-groq==0.1.6 \
    transformers==4.38.2 \
    sentence-transformers==3.0.1 \
    unstructured==0.16.5 \
    unstructured[pdf]==0.16.5 \
    peft==0.7.1

"""Given an access using groq Api"""

import getpass
import os

if "GROQ_API_KEY" not in os.environ:
  os.environ["GROQ_API_KEY"] = getpass.getpass("GROQ API Key:")




# Document Loader

from langchain.document_loaders import TextLoader
loader = TextLoader('/content/drive/MyDrive/Colab Notebooks/Colab Notebooks/india.txt')
documents = loader.load()

documents

print(documents)

import textwrap

def wrap_text_preserve_newlines(text, width=110):
  #Splite the input text into lines based on newline characters
  lines = text.split('\n')

  #Wrap each line individually
  wrapped_lines = [textwrap.fill(line, width=width) for line in lines]

  #Join the wrapper
  wrapped_text = '\n'.join(wrapped_lines)

  return wrapped_text

print(wrap_text_preserve_newlines(str(documents[0])))

#Text Splitters

from langchain.text_splitter import CharacterTextSplitter
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

len(docs)

#!pip install -U langchain-huggingface sentence-transformers

from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings()

#embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')

#!pip install faiss-gpu
!pip install faiss-cpu

from langchain.vectorstores import FAISS
db = FAISS.from_documents(docs, embeddings)



query = "explain about Politics"
docs = db.similarity_search(query)

print(wrap_text_preserve_newlines(str(docs[0].page_content)))